{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/cads-logo.png\" style=\"height: 100px;\" align=left> \n",
    "<img src=\"../images/python-logo.png\" style=\"height: 100px;\" align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Data Analysis\n",
    "Day 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Content Outline \n",
    "1. [t-distribution](#tdist)\n",
    "2. [Inference](#inference)\n",
    "    * [A. Point Estimation](#pointest)\n",
    "    * [B. Interval Estimation](#intest)\n",
    "    * [C.  Hypothesis testing](#hypothesis) \n",
    "3. [One-sample hypothesis tests](#onesample) \n",
    "    * [One-sample test for proportions](#onesampleprop)\n",
    "    * [One-sample test for means](#onesamplemean)\n",
    "4. [Two-sample hypothesis tests](#twosample)\n",
    "    * [C ---> Q](#ctoq)\n",
    "        * Unpaired two-sample test for proportions\n",
    "        4. [Unpaired two-sample test for means](#twosampletunpairedmeans)\n",
    "        5. [Paired two-sample test](#twosampletpaired)\n",
    "5. [Two (or more) sample hypothesis tests](#ntests)\n",
    "    - [C ---> Q](#ctoqn)\n",
    "        - [One-way ANOVA](#anova)\n",
    "    - [C ---> C](#ctoc)\n",
    "        - [Chi-square test for independence](#chisq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from scipy.stats import norm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. t-distribution<a name=\"tdist\"></a>\n",
    "\n",
    "We have seen that random variables can be visually modeled by many different sorts of shapes, and we call these shapes distributions. Several distributions arise so frequently that they have been given special names, and they have been studied mathematically. \n",
    "\n",
    "The **t-distribution** is another bell-shaped (unimodal and symmetric) distribution, like the normal distribution; and the center of the t-distribution is standardized at zero, like the center of the standard normal distribution which we call it z-distribution as well.\n",
    "\n",
    "Like all distributions that are used as probability models, the normal and the t-distribution are both scaled, so the total area under each of them is 1.\n",
    "\n",
    "So how is the t-distribution fundamentally different from the normal distribution? The **spread**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following picture illustrates the fundamental difference between the normal distribution and the t-distribution:\n",
    "\n",
    "<img src='../images/tDist.jpg'>\n",
    "\n",
    "The t-distribution has slightly less area near the expected central value than the normal distribution does, and has correspondingly more area in the \"tails\" than the normal distribution does. (It’s often said that the t-distribution has \"fatter tails\" or \"heavier tails\" than the normal distribution.)\n",
    "\n",
    "This reflects the fact that the t-distribution has a larger spread than the normal distribution. The same total area of 1 is spread out over a slightly wider range on the t-distribution, making it a bit lower near the center compared to the normal distribution, and giving the t-distribution slightly more probability in the ‘tails’ compared to the normal distribution.\n",
    "\n",
    "Therefore, the t-distribution ends up being the appropriate model in certain cases where there is more variability than would be predicted by the normal distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "There’s actually an entire family of t-distributions. They all have similar formulas (but the math is beyond the scope of this introductory course in statistics), and they all have slightly \"fatter tails\" than the normal distribution. But some are closer to normal than others. The t-distributions that are closer to normal are said to have higher \"degrees of freedom\" (that’s a mathematical concept that we won’t use in this course, beyond merely mentioning it here). So, there’s a t-distribution \"with one degree of freedom,\" another t-distribution \"with 2 degrees of freedom\" which is slightly closer to normal, another t-distribution \"with 3 degrees of freedom.\" which is a bit closer to normal than the previous ones, and so on.\n",
    "\n",
    "The following picture illustrates this idea with a few t-distributions (note that “degrees of freedom” is shown by $\\nu$):\n",
    "\n",
    "<img src='../images/Student_t_pdf.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inference<a name=\"inference\"></a>\n",
    "\n",
    "\n",
    "Our ultimate goal in statistical data analysis is using a sample to make inferences or draw conclusions about the population from which it was drawn.<br><br>\n",
    "<img src='../images/BigPic.png'><br><br>\n",
    "Our choice of the type of inference depends on the type of the variable of interest.\n",
    "We introduce three forms of statistical inference in this unit, each one representing a different way of using the information obtained in the sample to draw conclusions about the population. These forms are:\n",
    "* Point estimation\n",
    "* Interval estimation\n",
    "* Hypothesis testing\n",
    "\n",
    "## A. Point Estimation <a name=\"pointest\"></a>\n",
    "We estimate an unknown parameter using a **single number** that is calculated from the sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Based on sample results, we estimate that $p$, the proportion of Malaysian adults who are in favor of increasing taxes on tobacco products, is 0.6.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Interval Estimation <a name=\"intest\"></a>\n",
    "We estimate an unknown parameter using an **interval of values** that is likely to contain the true value of that parameter and state how confident we are that this interval indeed captures the true value of the parameter. \n",
    "\n",
    "Confidence intervals are not perfect. A 95% confidence interval implies that in repeated samples, 19 in 20 confidence intervals will capture the value of the population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Based on sample results, we are 95% confident that $p$, the proportion of Malaysian adults who are in favor of increasing taxes on tobacco products, is between 0.57 and 0.63. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1- Interval Estimation for Population Proportion (Categorical Variable)\n",
    "\n",
    "Suppose we are interested in the population proportion of a categorical variable. \n",
    "\n",
    "* **Step 1**: We collect data from a sample of our population of size  $n$\n",
    "* **Step 2**: The values of $\\hat p$ follow a normal distribution with (unknown) mean $p$ and standard deviation $\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}$. As we do not know the population proportion $p$, we use the sample proportion $\\hat p$. \n",
    "* **Step 3**:  According to the Standard Deviation Rule, this means that:\n",
    "    * We are 95% confident that the population proportion $p$ falls within $2*\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}$ of our estimate $\\hat p$.\n",
    "    * A 95% confidence interval for the population proportion $p$ is:\n",
    "$$\\left(\\hat p - 2*\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}, \\hat p + 2*\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}\\right)$$\n",
    "\n",
    "Here, then, is the general result:\n",
    "\n",
    "**Suppose a random sample of size n is taken from a population for a categorical variable whose proportion (p) is unknown. A 95% confidence interval (CI) for p is: $$\\left(\\hat p - 2*\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}, \\hat p + 2*\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}\\right)$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "A few days before a snap election, a polling organisation would like to estimate $p$, the proportion of eligible voters who support Candidate A. They choose a random sample of size 1000 and recorded their opinion. $71\\%$ of the sample support this candidate. How do you estimate the proportion of the people in the constituency who will vote for this candidate?\n",
    "\n",
    "**Point estimate:**  $\\hat p = 71\\%$<br>\n",
    "\n",
    "**Interval estimate:** According to the *central limit theorem*, sample proportion, $\\hat p$, follows the normal distribution $$\\hat p \\sim Normal\\left(mean=p, sd=\\sqrt{\\frac {{\\hat p }(1-{\\hat p})}{n}}\\right)$$\n",
    "\n",
    "So, we can say $\\bar p$ follows the normal distribution $$Normal\\left(mean=p , sd=\\sqrt{\\frac {{0.71}(1-{0.71})}{1000}}\\right)$$\n",
    "$$Normal(mean=p, sd=0.014)$$\n",
    "where $p$ is the population proportion. \n",
    "Therefore, we can say that \n",
    "* there is 95% chance that $p$ falls within 2$\\sigma_{\\bar p}$ of $\\hat p$. \n",
    "* Using the empirical rule, we can say the 95% confidence interval for $p$ is $({\\hat p}-2\\sigma_{\\bar p} , {\\hat p}+2\\sigma_{\\bar p}) = (0.71-2*0.014, 0.71+2*0.014) = (0.68, 0.73)$, where $\\sigma_{\\bar p}=\\sqrt{\\frac {\\hat p(1-{\\hat p})}{n}}$. \n",
    "* This means that we are 95% confident that $p$ lies within the interval (0.68, 0.73).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "Several public health researchers conducted a study to look at the connection between watching actors smoking in movies and initialising of smoking among adolescents. In the study, 6,522 teenagers aged 10-14 who had never tried smoking were randomly selected. Of those who subsequently tried smoking for the first time, 38% were exposed to smoking in the movies.\n",
    "\n",
    "- A. Estimate the proportion of all U.S. adolescents ages 10-14 who started smoking after seeing actors smoke in movies by constructing a 95% confidence interval.\n",
    "- B. Construct a 99.7% confidence interval for $p$. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2- Interval Estimation for Population Mean (Numerical Variable)\n",
    "\n",
    "Suppose we are interested in the mean of a numerical variable from a population. \n",
    "\n",
    "**- Case1:** We assume the population standard deviation ($\\sigma$) is **known**. \n",
    "\n",
    "* **Step 1:** We collect data from a sample of our population of size $n$\n",
    "* **Step 2:** The values of $\\bar x$ follow a normal distribution with (unknown) mean $\\mu$ and standard deviation $\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt n}$ (known, since both $\\sigma$ and $n$ are known). \n",
    "* **Step 3:** According to the Standard Deviation Rule, this means that:\n",
    "    * There is a 95% chance that our population mean $\\mu$ will fall within $2*\\frac{\\sigma}{\\sqrt n}$ of $\\hat \\mu$\n",
    "    * A 95% confidence interval for the population mean \n",
    "    $$\\mu \\in \\left(\\bar x - 2* \\frac{\\sigma}{\\sqrt n}, \\bar x + 2* \\frac{\\sigma}{\\sqrt n}\\right)$$\n",
    "\n",
    "Here, then, is the general result:\n",
    "\n",
    "**Suppose a random sample of size n is taken from a normal population of values for a quantitative variable whose mean ($\\mu$) is unknown, when the standard deviation ($\\sigma$) is given. A 95% confidence interval (CI) for $$\\mu \\in \\left(\\bar x - 2* \\frac{\\sigma}{\\sqrt n}, \\bar x + 2* \\frac{\\sigma}{\\sqrt n}\\right)$$**\n",
    "\n",
    "**- Case2:** We assume the population standard deviation ($\\sigma$) is **unknown**. \n",
    "In this case, we can replace $\\sigma$ with s, where s is the standard deviation of the sample however, the central limit theorem will not be valid anymore and $\\bar x$ will not follow normal distribution. Instead, $ t = \\frac {\\bar x - \\mu}{\\frac {s}{\\sqrt(n)}}$ will follow t-distribution with degree of freedom n - 1, where n is the sample size.\n",
    "\n",
    "$$t^* = \\frac {\\bar x - \\mu}{\\frac {s}{\\sqrt n}}$$\n",
    "\n",
    "$$t^* \\sim t(n - 1) $$\n",
    "Therefore, for each confidence interval $t^*$ should be calculated such that: \n",
    "$$\\mu \\in \\left(\\bar x - t^* * \\frac{s}{\\sqrt n}, \\bar x + t^* * \\frac{s}{\\sqrt n}\\right)$$.\n",
    "\n",
    "Because $t^* \\sim t(n - 1) $, the above interval depends on both the **confidence level and the sample size n**. For instance, the 95% cut-off in the following t-distribution can be calculated using python by $t^* = t.ppf(0.975, n-1)$\n",
    "\n",
    "<img src='../images/t_dist_int.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "    <b>Numerical Variable Mean</b>: Suppose we are interested in studying the average IQ of students in a university. To do so, we collect a random sample of size 100 from the students in this university. Assume the mean of the IQ level of these students is 115, and its standard deviation is $\\sigma=5$. What is $\\mu$, the mean of the IQ level of the population which is the whole students at this university?\n",
    "\n",
    "> **Point estimate:**  $\\hat \\mu= 115$<br>\n",
    "> **Interval estimate:** $\\hat \\mu=115, \\sigma=5, n=100$.<br>\n",
    "> * Note that $\\frac{5}{\\sqrt{100}}$ is the standard deviation of the sampling distribution of sample estimates $\\bar x$ - the *standard error*, $\\sigma_{\\bar x}$. \n",
    "> * According to the *central limit theorem*, the distribution of the sample means $\\bar x$(s) follows a normal distribution:  \n",
    "> $$\\bar x \\sim Normal(mean=\\mu, sd=\\frac{\\sigma}{\\sqrt{n}})$$ \n",
    "> * Since $\\hat \\mu$ is our estimate of $\\mu$, the sample means are distributed as $$\\bar x\\sim Normal(115, 0.5)$$\n",
    "> * Recall the standard deviation rule: \n",
    "<img src='../images/IQ.png'>\n",
    "\n",
    "Since two standard errors = 1, the statement:\n",
    "> \"There is a **95% chance** that the sample mean $\\bar x$ falls within 1 unit of $\\mu$\". \n",
    "\n",
    "can be rephrased as: \n",
    "> \"We are 95% confident that the population mean $\\mu$ falls within 1 units of $\\bar x$\".\n",
    "\n",
    "Given a sample mean of $\\bar x=115$, we can be **95% confident** that $\\mu$ falls within 1 unit of 115, or in other words that $\\mu$ is covered by the interval $(115 - 1, 115 + 1) = (114,116)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "An educational researcher was interested in estimating $\\mu$, the mean score on the total SAT scores of all college students in a state. To this end, the researcher has chosen a random sample of 650 college students from his state, and found that their average SAT score is 1425. Based on a large body of research that was done on the SAT, it is known that the scores roughly follow a normal distribution with the standard deviation $\\sigma=300$.\n",
    "\n",
    "- A. Based on this information, construct a 95% confidence interval for $\\mu$.\n",
    "- B. Construct a 99.7% confidence interval for $\\mu$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "What is the relationship between the level of the confidence and the length of the confidence interval?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Repeat the above example if population standard deviation is unknown but sample standard deviation is 4.5. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    " \n",
    "x_bar = 115\n",
    "n = 100\n",
    "s = 4.5\n",
    "df = n - 1\n",
    "c = 0.95\n",
    "beta = c + (1 - c)/2\n",
    "t_star = t.ppf (beta , df)\n",
    "print('Population mean estimate by 95% confidence interval: (', \n",
    "      round(x_bar-t_star*s/(n ** .5),4), ', ', round(x_bar+t_star*s/(n ** .5),4), ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "Repeat the above exercise it the population standard deviation is unknown, but the sample standard deviation is 298.\n",
    "\n",
    "- A. Based on this information, construct a 95% confidence interval for $\\mu$.\n",
    "- B. Construct a 99.7% confidence interval for $\\mu$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.  Hypothesis testing <a name=\"hypothesis\"></a>\n",
    "\n",
    "The disciplinary committee of a university investigates a student suspected of cheating on an exam. There are two opposing claims in this case:\n",
    "\n",
    "* The student claims that he did not cheat on the exam.\n",
    "* The lecturer claims that the student did cheat on the exam.\n",
    "\n",
    "The committee assumes the student to be innocent unless the lecturer can prove that the student is guilty. Therefore, the committee asks the instructor to provide evidence to support his claim. The lecturer explains that he set two versions of the exam, and on four separate exam questions, the student answered with numbers provided in the other version of the exam.\n",
    "\n",
    "The committee agrees that it would be extremely unlikely for the lecturer to have such strong evidence if the student did not cheat. In other words, the lecturer provided strong enough evidence for the committee to **reject** the student's claim, and **conclude** that the student did cheat on the exam.\n",
    "\n",
    "**Hypothesis testing** is defined as **assessing evidence provided by the data in favour of or against some claim about the population.**\n",
    "\n",
    "Here is how the process of statistical hypothesis testing works:\n",
    "\n",
    "* **Step 1:** We have **two claims** about what is going on in the population: claim 1 and claim 2. In the story above, where the instructor's claim challenges the student's claim, **claim 1 is challenged by claim 2**. In hypothesis testing, we usually test 'claims' (or hypotheses) about the value of population parameter(s) or about whether a relationship exists between two variables in the population.\n",
    "* **Step 2:** We choose a **sample**, collect relevant data and summarize them. This is similar to the instructor collecting evidence from the student's exam.\n",
    "* **Step 3:** We figure out **how likely** it is to observe data like the data we got, had claim 1 been true. (Note that the wording \"how likely ...\" implies that this step requires some kind of probability calculation). In our story, the committee members assessed how likely it is to observe the evidence provided by the instructor if the student's claim of not cheating was true.\n",
    "* **Step 4:** Based on what we found in the previous step, we make our decision:\n",
    "    - If we find that it would be extremely unlikely to observe the data that we observed if claim 1 were true, then we have strong evidence against claim 1, and we **reject** it in favour of claim 2.\n",
    "    - If we find that observing the data that we observed is not very unlikely if claim 1 were true, then we do not have enough evidence against claim 1, and therefore we **cannot reject** it in favour of claim 2.\n",
    "\n",
    "In our story, the committee decided that it would be extremely unlikely to find the evidence that the lecturer provided if the student did not cheat. In other words, the members felt that it is extremely unlikely that it is just a coincidence that the student used the numbers from the other version of the exam on four separate problems. The committee members therefore decided to reject the student's claim and concluded that the student had, indeed, cheated on the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "A recent study estimated that 14.6% of all upper secondary school students in Malaysia smoke.(https://tobaccoinduceddiseases.biomedcentral.com/articles/10.1186/s12971-016-0108-5). The head of a district education office suspects that the proportion of smokers may be lower there. In hopes of confirming her claim, she chooses a random sample of 400 upper secondary high school students in the district, and finds that 50 of them are smokers.\n",
    "\n",
    "Let's analyze this example using the 4 steps outlined above:\n",
    "\n",
    "**Stating the claims:**\n",
    "\n",
    "There are two claims here:\n",
    "\n",
    "* *claim 1:* The proportion of smokers in the district is 0.146.\n",
    "* *claim 2:* The proportion of smokers at Goodheart is less than 0.146.\n",
    "\n",
    "Claim 1 basically says \"nothing special goes on in this district; the proportion of smokers there is no different from the proportion in the entire country.\" This claim is challenged by the head of the district office, who suspects that the proportion of smokers in her district is lower.\n",
    "\n",
    "**Choosing a sample and collecting data:**\n",
    "\n",
    "A sample of $n = 400$ was chosen, and summarizing the data, we find that the sample proportion of smokers is $\\hat p = \\frac {50}{400} = 0.125$\n",
    "\n",
    "While it is true that 0.125 is less than 0.146, it is not clear whether this is strong enough evidence against claim 1.\n",
    "\n",
    "**Assessment of evidence:**\n",
    "\n",
    "To assess whether the data provide strong enough evidence against claim 1, we need to ask ourselves: How surprising is it to get a sample proportion as low as $\\hat p = 0.125$ (or lower) if claim 1 is true?\n",
    "\n",
    "In other words, we need to find how likely it is that in a random sample of size $n = 400$ taken from a population where the proportion of smokers is $p = 0.146$ we'll get a sample proportion as low as $\\hat p = 0.125$ (or lower).\n",
    "\n",
    "It turns out that the probability that we'll get a sample proportion as low as $\\hat p = 0.125$ (or lower) if $p = 0.146$ is roughly 0.117 (do not worry about how this was calculated at this point).\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "We found that there is a probability of 0.117 of observing data like that observed if claim 1 were true.\n",
    "\n",
    "Now you have to decide ... Do you think that a probability of 0.117 makes our data rare enough (surprising enough) under claim 1 so that the fact that we did observe it is enough evidence to reject claim 1? Or do you feel that a probability of 0.117 means that the data we observed are not very likely when claim 1 is true, but not unlikely enough to conclude that getting such data is sufficient evidence to reject claim 1? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing (General Case)\n",
    "\n",
    "* **Step 1: Stating the claims**: Our aim is to decide between two opposing points of view, *Claim 1* and *Claim 2*. In hypothesis testing, Claim 1 is called the **null hypothesis** (denoted $H_0$), and Claim 2 plays the role of the **alternative hypothesis** (denoted $H_a$). \n",
    "\n",
    "* **Step 2: Choosing a sample and collecting data**: We look at sampled data to draw conclusions about the entire population. In hypothesis testing, based on the data, you draw conclusions about whether there is enough evidence to reject $H_0$.\n",
    "\n",
    "* **Step 3: Assessing the evidence**: This is the step where we calculate how likely is it to get data like that observed when $H_0$ is true. We use the **p-value** to assess the evidence. It is **the probability of observing a test statistic as extreme as (or even more extreme than) that observed assuming that the null hypothesis is true.**\n",
    "\n",
    "<font color='red'>\n",
    "\n",
    "p-value = The probability of observing a test statistic as extreme as (or even more extreme than) that observed assuming that the null hypothesis is true.</font> \n",
    "\n",
    "* **Step 4: Making conclusions**: Since our conclusion is based on how small the p-value is, it would be nice to have some kind of threshold or cutoff that will help determine how small the p-value must be, or how \"rare\" (unlikely) our data must be when $H_0$ is true, for us to conclude that we have enough evidence to reject $H_0$.\n",
    "\n",
    "This cutoff has a special name. It is called the **significance level** of a test and is usually denoted by the Greek letter $\\alpha$. The most commonly used significance level is $\\alpha = 0.05$ (or 5\\%). We use the following decision rule:\n",
    "- if the p-value < $\\alpha$ (usually 0.05 or 5%), then the data we got is considered to be \"rare (or surprising) enough\" when $H_0$ is true, and we say that the data provide significant evidence against $H_0$, so we reject $H_0$ and accept $H_a$.\n",
    "- if the p-value > $\\alpha$ (usually 0.05 or 5%), then our data are not considered to be \"surprising enough\" when $H_0$ is true, and we say that our data do not provide enough evidence to reject $H_0$ (or, equivalently, that the data do not provide enough evidence to accept $H_a$).\n",
    "    \n",
    "Linked to the concept of a *significance level* is the **confidence level** . A significance level of 0.05 or 5% corresponds with a 95% confidence level. The confidence level is associated with the confidence interval. For instance, you can construct a 95% confidence interval, where 95% refers to the confidence level. Just like p-values, confidence intervals can be used to do hypothesis testing. The decision rule for confidence intervals is as follows: \n",
    "- If sample parameter falls outside the 95% confidence interval, reject $H_0$ in favour of $H_a$. \n",
    "- If sample parameter falls inside the 95% confidence interval, do not reject $H_0$.\n",
    "    \n",
    "Note that the null hypothesis can never be accepted - you can only reject the null hypothesis in favour of the alternative hypothesis, or fail to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. One-sample hypothesis testing<a name=\"onesample\"></a> \n",
    "\n",
    "<img src='../images/sample-prop-table.png'>\n",
    "\n",
    "\n",
    "## Proportions<a name=\"onesampleprop\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Our workers are known to produce 20% defective products, and are sent for retraining. After the training, 400 products produced are chosen at random and 64 are found to be defective (proportion $\\hat p=\\frac{64}{400}=0.16$). Do the data provide enough evidence that the proportion of defective products produced by our workers, $p$ has been reduced as a result of the training?\n",
    "\n",
    "Based on our problem, we formulate the following hypotheses:\n",
    "* $H_0: p = 0.20$ (No change; the training did not help, $p_0=0.20$)\n",
    "* $H_a: p < 0.20$ (The training was effective)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 64\n",
    "n=400\n",
    "p_hat= x/n\n",
    "p0=0.2\n",
    "sd=(p0 * (1 - p0)/n)**.5\n",
    "\n",
    "#Solution1\n",
    "p_value = norm.cdf(p_hat, p0, sd)\n",
    "\n",
    "alpha = .05\n",
    "if p_value < alpha: \n",
    "    print(\"\\np_value = {}, Reject the null hypothesis, in favour of the alternative\\\n",
    "    that the proportion of defective products is less than 0.2 and it has been reduced\\\n",
    "    as a result of the training\".format(round(p_value, 3)))\n",
    "else: \n",
    "    print(\"\\np_value = {}, CANNOT Reject the null hypothesis. Therefore, there is not\\\n",
    "    strong enough evidence to prove the proportion of defective products has been reduced\".format(round(p_value,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution2\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "p_value = proportions_ztest(count=x , nobs=n, value=p0, prop_var = p0, alternative='smaller')[1]\n",
    "\n",
    "alpha = .05\n",
    "if p_value < alpha: \n",
    "    print(\"\\np_value = {}, Reject the null hypothesis, in favour of the alternative\\\n",
    "    that the proportion of defective products is less than 0.2 and it has been reduced\\\n",
    "    as a result of the training\".format(round(p_value, 3)))\n",
    "else: \n",
    "    print(\"\\np_value = {}, CANNOT Reject the null hypothesis. Therefore, there is not\\\n",
    "    strong enough evidence to prove the proportion of defective products has been reduced\".format(round(p_value,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "    Polls on certain topics are conducted routinely to monitor changes in the public's opinions over time. One such topic is the death penalty. In 2013, a poll estimated that 91% of 1,535 Malaysian adults surveyed support the death penalty for people convicted of murder. In a more recent poll, 890 out of 1,000 Malaysian adults chosen at random were in favor of the death penalty for convicted murderers. Do the results of this poll provide evidence that the proportion of Malaysian adults who support the death penalty for convicted murderers ($p$) changed between 2013 and the later poll?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means <a name=\"onesamplemean\"></a>\n",
    "We need to distinguish between two cases: where the population standard deviation ($\\sigma$) is known, and the case where $\\sigma$ is unknown.\n",
    "\n",
    "- If $\\sigma$ is **known**, the test is called the **z-test** for the population mean $\\mu$ because the sample mean follows the **normal** distribution $Normal(mean=\\mu_0, std=\\frac {\\sigma}{\\sqrt {n}})$ where $n$ = sample size; $\\mu_0$ = population mean according to the null hypothesis, and $\\sigma$ = population standard deviation. Therefore, the test statistic $z=\\frac {{\\bar x}-\\mu_0}{\\frac {\\sigma}{\\sqrt {n}}}$, which is the standardised sample mean, follows a **z-distribution**, or a standard normal distribution. \n",
    "\n",
    "<img src='../images/sample_mean_table1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "The SAT, a standardised test for college admissions in the US, is constructed so that scores in each portion have a national average of 500 and standard deviation of 100. The distribution is close to normal. The Marketing department of your college believes that in recent years the college attracts students who are more math-inclined. A random sample of 15 students from a recent cohort at your College had an average math SAT (SAT-M) score of 550. Does this provide enough evidence for the dean to conclude that the mean SAT-M of all your college's students is higher than the national mean of 500? Assume that the standard deviation of 100 applies also to all students at your college.\n",
    "\n",
    "**Solution 1:**\n",
    "\n",
    "The sampling distribution of $\\bar x$ under the null hypothesis is normal: $$\\bar x \\sim Normal(mean=\\mu_0, std=\\frac {\\sigma}{\\sqrt {n}})$$, \n",
    "where $\\mu_0 = 500$ and $\\sigma$ = standard deviation of population\n",
    "\n",
    "- H0: mean = 500\n",
    "- Ha: mean > 500\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0 = 500\n",
    "sigma = 100\n",
    "x_bar = 550\n",
    "n = 15\n",
    "sd = sigma/n**.5\n",
    "p_value = 1 - norm.cdf(x_bar, mu_0, sd)\n",
    "\n",
    "if p_value < alpha: \n",
    "    print(\"p_value = {}, Reject the null hypothesis in favour of the alternative that the \\\n",
    "    mean of SAT-M of new students at your college is higher than the mean of SAT-M of population.\".format(round(p_value, 3)))\n",
    "else: \n",
    "    print(\"p_value = {}, CANNOT Reject the null hypothesis. Therefore, \\\n",
    "    there is not strong enough evidence that the mean of SAT-M of new \\\n",
    "    students at your college is higher than the mean of SAT-M of population.\".format(round(p_value, 3))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "Human pregnancy is known to have a mean of 266 days and a standard deviation of 16 days. Based on records from a large hospital, a random sample of 30 women who were smoking and/or drinking alcohol during their pregnancy and their pregnancy lengths are recorded. We calculated the average pregnancy length of these women as 258.78. Do the data provide enough evidence to support the (well-known) fact that women who smoke and/or drink alcohol during their pregnancy have shorter pregnancies than women in general (in other words, are more likely to have premature labor)?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If $\\sigma$ is **unknown**, the test is called the **t-test** for the population mean $\\mu$ because the standardised sample mean follows a **t-distribution**. In other words, the test statistic $t=\\frac {{\\bar x}-\\mu_0}{\\frac {s}{\\sqrt {n}}}$ follows t-distribution $t \\sim t(n-1)$ where s is the standard deviation of the sample, and $n$ is the sample size.\n",
    "\n",
    "<img src='../images/sample_mean_table2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "A certain prescription medicine is supposed to contain an average of 250 parts per million (ppm) of a certain chemical. If the concentration is higher than this, the drug may cause harmful side effects; if it is lower, the drug may be ineffective. The manufacturer wants to know whether the mean concentration in a large shipment conforms to the target level of 250 ppm. \n",
    "\n",
    "A simple random sample of 100 portions is tested, and the sample mean concentration is found to be 246 ppm with a sample standard deviation of 12 ppm.\n",
    "\n",
    "The hypotheses are:   \n",
    "\n",
    "* $H_0: \\mu = 250$\n",
    "* $H_a: \\mu \\neq 250$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0, n, x_bar, s = 250, 100, 246, 12\n",
    "t_score = (x_bar - mu_0)/(s/n**.5)\n",
    "p_value = 2 * t.cdf(-abs(t_score), df = n - 1)\n",
    "\n",
    "if p_value < alpha: \n",
    "    print(\"p_value = {}, Reject the null hypothesis in favour of the alternative that the mean\\\n",
    "    concentration does NOT conform to the target level of 250 ppm\".format(round(p_value, 3)))\n",
    "else: \n",
    "    print(\"p_value = {}, CANNOT Reject the null hypothesis. Therefore, there is not strong enough\\\n",
    "    evidence that the mean concentration does NOT conform to the target level of \\\n",
    "    250 ppm\".format(round(p_value, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "    On average, a Finnish consumes 12kg of coffee in a year, which is 5 cups a day per person. A Finnish university wants to know whether their students tend to drink more coffee than the national average. They ask 50 students how many cups of coffee they drink each day and found their average number of drinks is $\\bar{x}=5.2$, with std dev $s=1.5$. Do they have enough evidence that their students drink more than the national average?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "The mean of crude birth rate has been 16.7 per 1000 population in Malaysia in 2014. The following data shows crude birth rate from January to March 2019. Does the data prove a significant difference in 2019 comparing to 2014?\n",
    "\n",
    "- H0: mu = 16.7\n",
    "- Ha: mu != 16.7\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../data/CBR.csv\")\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample.CBR\n",
    "sample_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n***************** Solution1 *****************\\n')\n",
    "\n",
    "mu_0=16.7\n",
    "x_bar = np.mean(sample_data)\n",
    "print('x_bar = ', x_bar)\n",
    "s = np.std(sample_data, ddof=1)\n",
    "print('s = ', s)\n",
    "n = len(sample_data)\n",
    "print('n = ', n)\n",
    "t_score = (x_bar - mu_0)/(s/(n**.5))\n",
    "print('t_score = ', t_score)\n",
    "\n",
    "p_value = 2*t.cdf(-abs(t_score), df = n-1)\n",
    "\n",
    "if p_value < alpha: \n",
    "    print(\"\\np_value = {}, Reject the null hypothesis in favour of the alternative that the mean\\\n",
    "    of crude birth rate is different in 2019 comparing that in 2014.\".format(round(p_value, 3)))\n",
    "else: \n",
    "    print(\"\\np_value = {}, CANNOT Reject the null hypothesis. Therefore, there is not strong enough\\\n",
    "    evidence that the mean of crude birth rate is different in 2019 comparing that in 2014.\".format(round(p_value, 3)))\n",
    "\n",
    "print('\\n***************** Solution2 *****************\\n')\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_1samp\n",
    "p_value=ttest_1samp(sample_data , mu_0).pvalue\n",
    "\n",
    "if p_value < alpha: \n",
    "    print(\"p_value = {}, Reject the null hypothesis in favour of the alternative that the mean\\\n",
    "    of crude birth rate is different in 2019 comparing that in 2014.\".format(round(p_value, 3)))\n",
    "else: \n",
    "    print(\"p_value = {}, CANNOT Reject the null hypothesis. Therefore, there is not strong enough\\\n",
    "    evidence that the mean of crude birth rate is different in 2019 comparing that in 2014.\".format(round(p_value, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "In the above example, can we say crude birth rate has been decreased in 2019? \n",
    "    </div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Two-sample hypothesis test<a name=\"twosample\"></a>\n",
    "\n",
    "In the previous sections we performed inference for one variable. If this variable was categorical, we perform one-sample hypothesis test for proportions. If the variable was numerical/quantitative, we perform one-sample hypothesis test for mean.\n",
    "\n",
    "In this section, we look at inference about relationships between two variables in a population, based on an observed relationship between variables in a sample.\n",
    "\n",
    "Assume we are interested in studying whether a relationship exists between the variables $x$ and $y$ in a population of interest. We choose a random sample and collect data on both variables from the subjects. Our goal is to determine whether these data provide strong enough evidence for us to generalize the observed relationship in the sample and conclude (with some acceptable and agreed-upon level of uncertainty) that a relationship between $x$ and $y$ exists in the entire population.\n",
    "\n",
    "* $H_0:$ There is no relationship between $x$ and $y$\n",
    "* $H_a:$ There is a significant relationship between $x$ and $y$\n",
    "\n",
    "## C ---> Q<a name=\"ctoq\"></a>\n",
    "We consider hypothesis testing where $x$, the explanatory variable, is a **categorical** variable and $y$, the response variable, is a **quantitative** variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "To investigate this relationship between year in university and GPA, we can divide the population of the university students in Malaysia into 4 sub-populations. Within each of these four groups, we are interested in the GPA.\n",
    "\n",
    "The inference must therefore involve the 4 sub-population means:\n",
    "\n",
    "* $\\mu_1:$ mean GPA among first year undergraduates in Malaysia\n",
    "* $\\mu_2:$ mean GPA among second year undergraduates in Malaysia\n",
    "* $\\mu_3:$ mean GPA among third year undergraduates in Malaysia\n",
    "* $\\mu_4:$ mean GPA among fourth year undergraduates in Malaysia\n",
    "\n",
    "So, we need to compare these four means. If we infer that not all these four means are equal (i.e., that there are some differences in GPA across years in university) then that's equivalent to saying GPA is related to year in university. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Assume $x$ is drinking/not_drinking alcohol, and $y$ is reaction time of the driver. We are interested to explore the impact of drinking two beers on the driver's reaction time. In this case, we measure the reaction time of 40 drivers, **before** and **after** drinking two beers.\n",
    "\n",
    "<img src='../images/Paired.png'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-sample t-test of means for unpaired samples  <a name=\"twosampletunpairedmeans\"></a>\n",
    "\n",
    "<img src='../images/2sample_mean_table.png'>\n",
    "\n",
    "The two-sample t-test can be safely used as long as the following conditions are met:\n",
    "\n",
    "1. **Both populations are normally distributed**, or more specifically, the distribution of $y$ in both sub-populations is normal, and both **samples are random** (or at least can be considered as such). In practice, checking normality in the sub-populations is done by looking at each of the samples using a histogram and checking whether there are any signs that the populations are not normal. Such signs could be extreme skewness and/or extreme outliers.\n",
    "\n",
    "2. The populations are known or discovered not to be normal, but the **sample size of each of the random samples is large enough** (we can use the rule of thumb that $n> 30$ is considered large enough).\n",
    "\n",
    "The two-sample t-test statistic is:\n",
    "\n",
    "$$t = \\frac{\\bar y_1-\\bar y_2}{\\sqrt{\\frac{{s_1}^2}{n_1}+\\frac{{s_2}^2}{n_2}}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\bar y_1$ and $\\bar y_2$ are the sample means of the samples from sub-population 1 and sub-population 2 respectively.\n",
    "\n",
    "\n",
    "- $s_1$ and $s_2$ are the sample standard deviations of the samples from sub-population 1 and sub-population 2 respectively.\n",
    "\n",
    "\n",
    "- $n_1$ and $n_2$ are the sample sizes of the two samples.\n",
    "\n",
    "\n",
    "**Attention:**\n",
    "To understand the t-test statistic we need to know that \n",
    "* $\\bar y_1$ estimates $\\mu_1$ (mean of sub-population 1) and \n",
    "* $\\bar y_2$ estimates $\\mu_2$ (mean of sub-population 2). \n",
    "\n",
    "Therefore, $\\bar y_1 - \\bar y_2$ estimates $\\mu_1 -\\mu_2$ . \n",
    "\n",
    "$\\mu_1 -\\mu_2 = 0$ is the \"null value\" — what the null hypothesis, $H_0$, claims that $\\mu_1 -\\mu_2$ is.\n",
    "\n",
    "The denominator ${\\sqrt{\\frac{{s_1}^2}{n_1}+\\frac{{s_2}^2}{n_2}}}$ is the standard deviation of $\\bar y_1 - \\bar y_2$\n",
    "\n",
    "We therefore see that our test statistic, like the previous test statistics we encountered, has the structure:\n",
    "\n",
    "$$\\frac {Sample\\,Estimate - Null\\,Value}{Standard\\,Error}$$ and therefore, like the previous test statistics, measures (in standard errors) the difference between what the data tell us about the parameter of interest $\\mu_1 -\\mu_2$ (sample estimate) and what the null hypothesis claims the value of the parameter is (null value).\n",
    "\n",
    "The number of degrees of freedom is $\\nu$ where:\n",
    "\n",
    "$$\\nu = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{s_1^4}{n_1^2(n_1-1)} + \\frac{s_2^4}{n_2^2(n_2-1)}}$$\n",
    "\n",
    "Degrees of freedom refers to the number of number of observations that are free to vary when calculating a statistic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Assume we are interested in investigating the relationship between a patient having a heart attack and the level of cholesterol. The variables we have are:\n",
    "\n",
    "$x$: patient had heart attack (yes/no) ---> Categorical\n",
    "\n",
    "$y$: patient cholesterol level (number) ---> Quantitative\n",
    "\n",
    "We measured the cholesterol level of 38 heart attack patients (2 days after their attacks) and 40 other hospital patients who did not have a heart attack. \n",
    "\n",
    "For the 38 heart attack patients, the mean cholesterol level was 253.9 with a standard deviation of 47.7. For the 40 other hospital patients who did not have a heart attack, the mean cholesterol level was 193.1 with a standard deviation of 22.3. Are cholesterol levels different across the different groups?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- $H_0: \\mu_1-\\mu_2 = 0$\n",
    "- $H_a: \\mu_1-\\mu_2 \\neq 0$\n",
    "\n",
    "$n_1 = 38$;   $\\bar y_1 = 253.9$;   $s_1 = 47.7$ \n",
    "\n",
    "$n_2 = 40$;   $\\bar y_2 = 193.1$;   $s_2 = 22.3$ \n",
    "\n",
    "$$t = \\frac{\\bar y_1-\\bar y_2}{\\sqrt{\\frac{{s_1}^2}{n_1}+\\frac{{s_2}^2}{n_2}}} = \\frac{253.9-193.1}{\\sqrt{\\frac{{47.7}^2}{38}+\\frac{{22.3}^2}{40}}} = 7.150$$\n",
    "\n",
    "$$df = \\frac{(\\frac{47.7^2}{38} + \\frac{22.3^2}{40})^2}{\\frac{47.7^4}{38^2(38-1)} + \\frac{22.3^4}{40^2(40-1)}} = 51.84$$\n",
    "\n",
    "`p_value = 2*t.cdf(-abs(t), df)` = 2.8980437531650854e-09\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier, let's write a function `unpaired_t` that returns $t$ and $\\nu$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpaired_t(n_1, y_1, s_1, n_2, y_2, s_2): \n",
    "    t_score = (y_1-y_2)/(((s_1**2/n_1)+(s_2**2/n_2))**.5)\n",
    "    df=( (((s_1**2)/n_1)+((s_2**2)/n_2))**2 )/( (s_1**4)/((n_1**2)*(n_1-1)) + (s_2**4)/((n_2**2)*(n_2-1)) )\n",
    "    return(t_score, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1, y_1, s_1 =38, 253.9, 47.7\n",
    "n_2, y_2, s_2 =40, 193.1, 22.3\n",
    "\n",
    "t_score, df = unpaired_t(n_1, y_1, s_1, n_2, y_2, s_2)\n",
    "print('t_score = ', t_score)\n",
    "print('df = ', df)\n",
    "\n",
    "\n",
    "from scipy.stats import t\n",
    "p_value = 2*t.cdf(- abs(t_score), df)\n",
    "\n",
    "if p_value < alpha: \n",
    "    print(\"p_value = {}, Reject the null hypothesis in favour of the alternative that there IS \\\n",
    "    a relationship between cholesterol level and heart attack\".format(round(p_value, 9)))\n",
    "else:\n",
    "    print(\"p_value = {}, CANNOT Reject the null hypothesis: we have insufficient evidence for \\\n",
    "    a relationship between cholesterol level and heart attack\".format(round(p_value, 9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "To check the claim that the pregnancy length of women who smoke during pregnancy is shorter, on average, than the pregnancy length of women who do not smoke, a random sample of 35 pregnant women who smoke and a random sample of 35 pregnant women who do not smoke were chosen and their pregnancy lengths were recorded. \n",
    "\n",
    "$x$: smoke (yes/no) ---> Categorical variable\n",
    "\n",
    "$y$: pregnancy length ---> Quantitative variable\n",
    "\n",
    "Two methods can be used:\n",
    "\n",
    "1. calculating $t$ and $\\nu$ and then use the function `t.cdf`\n",
    "2. using `scipy.stats.ttest_ind` function\n",
    "\n",
    "The hypotheses are as follows: \n",
    "- $H_0: \\mu_1 - \\mu_2 = 0$ (There is no relationship between smoking and pregnancy length)\n",
    "- $H_a: \\mu_1 - \\mu_2 < 0$ (Pregnancy length of women who smoke is shorter than the pregnancy length of women who do not smoke)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/pregnancy.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1, sample2 = data.Smoke.dropna(), data.No_Smoke.dropna()\n",
    "\n",
    "# Solution1:\n",
    "print('\\n***************** Solution1 *****************\\n')\n",
    "\n",
    "\n",
    "\n",
    "n_1, y_1, s_1 = len(sample1), np.mean(sample1), np.std(sample1, ddof=1)\n",
    "n_2, y_2, s_2 = len(sample2), np.mean(sample2), np.std(sample2, ddof=1)\n",
    "\n",
    "t_score, df = unpaired_t(n_1, y_1, s_1, n_2, y_2, s_2)\n",
    "p_value = t.cdf(t_score, df)\n",
    "\n",
    "if p_value < alpha: \n",
    "    print('p_value = {}, Reject the null hypothesis in favour of the alternative that \\\n",
    "      Pregnancy length of women who smoke is shorter than the pregnancy length \\\n",
    "      of women who do not smoke'.format(p_value))\n",
    "else: \n",
    "    print('p_value = {}, CANNOT  Reject the null hypothesis: we do not have enough evidence \\\n",
    "    for a significant relationship between pregnancy length and heart smoking'.format(p_value))\n",
    "    \n",
    "# Solution2:\n",
    "print('\\n***************** Solution2 *****************\\n')\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "p_value = .5 *  ttest_ind(sample1, sample2, equal_var=False)[1]\n",
    "\n",
    "if p_value < alpha: \n",
    "    print('p_value = {}, Reject the null hypothesis in favour of the alternative that \\\n",
    "      Pregnancy length of women who smoke is shorter than the pregnancy length \\\n",
    "      of women who do not smoke'.format(p_value))\n",
    "else: \n",
    "    print('p_value = {}, CANNOT  Reject the null hypothesis: we do not have enough evidence \\\n",
    "    for a significant relationship between pregnancy length and heart smoking'.format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `scipy.stats.ttest_ind` we can directly test two independent samples without calculating the means, t-statistic and degrees of freedom: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "A researcher wanted to study whether men and women watch different amounts of YouTube. A random sample of 400 adults was chosen, comprising of 191 women and 209 men. At the end of the week, each of the 400 subjects reported the total amount of time (in minutes) that he or she watched YouTube during that week.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = pd.read_csv('../data/tv.csv')\n",
    "tv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-sample t-test for paired samples means <a name=\"twosampletpaired\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Drunk driving is one the main causes of car accidents. We want to know whether drivers are impaired after drinking two beers. A sample of 30 drivers was chosen, and their reaction times in an obstacle course were measured before and after drinking two beers. The variables we have are: \n",
    "\n",
    "$x$: Drinking alcohol (yes/no) ---> Categorical\n",
    "\n",
    "$y$: Reaction time of the driver ---> Quantitative\n",
    "\n",
    "Let $\\mu_1$ be the average of the reaction time before drinking 2 beers, and $\\mu_2$ be the average of the reaction time before drinking 2 beers.\n",
    "\n",
    "https://www.youtube.com/watch?time_continue=1&v=URPrSH0Lg_M\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/TwoPairedOne.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $H_0: \\mu_d = 0$ OR $\\mu_1 - \\mu_2 = 0$ \n",
    "- $H_a:\\mu_d < 0$ OR $\\mu_1 - \\mu_2 < 0$ If the driver is drunk it takes more time to react $\\mu_1 < \\mu_2$.\n",
    "\n",
    "Assume \n",
    "* mean of differences in the sample is -0.501, \n",
    "* standard deviation of differences is 0.868.\n",
    "\n",
    "and therefore\n",
    "* $\\bar x_d = -0.501$, \n",
    "* $s_d = 0.868$, \n",
    "* $n=30$, \n",
    "* $\\mu_0 = 0$\n",
    "\n",
    "$$t = \\frac {{\\bar x_d}-\\mu_0}{\\frac {s_d}{\\sqrt {n}}} = \\frac {-0.501}{\\frac {0.868}{\\sqrt {30}} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, x_d_bar, s_d, mu_0 =30, -0.501, 0.868, 0\n",
    "t_stat=(x_d_bar-mu_0)/(s_d/n**.5)\n",
    "t_stat \n",
    "df = n - 1\n",
    "p_value = t.cdf(t_stat, df)\n",
    "\n",
    "if p_value < alpha: \n",
    "    print(\"p_value = {}, reject the null hypothesis \\\n",
    "    in favour of the alternative that reaction time increases after drinking alcohol\".format(round(p_value, 7)))\n",
    "else: \n",
    "    print(\"p_value = {}, Cannot reject the null: not enough evidence for a relationship \\\n",
    "    between drinking alcohol (2 beers) and reaction time of the driver\".format(round(p_value, 7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "Suppose we want to evaluate the effectiveness of this course on the statistics skills of the students. Assume there are 100 students in a cohort. We record their scores in a sample statistics test **before** and **after** passing this course. Did our students' statistics skills improve after taking the class?\n",
    "\n",
    "Define $\\mu_d=\\mu_2-\\mu_1$\n",
    "\n",
    "- $H_0: \\mu_d = 0$ \n",
    "- $H_a: \\mu_d > 0$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.read_csv('../data/StatScore.csv')\n",
    "score.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diff = score.Score2 - score.Score1\n",
    "np.mean(score_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to run a paired t-test: \n",
    " - treat it as a one-sample t-test where we test the differences between the two samples. Naturally, the null hypothesis is that the difference between the two samples is 0. Use `scipy.stats.ttest_1samp`\n",
    " - pass the two samples directly to `scipy.stats.ttest_rel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp \n",
    "ttest_result = ttest_1samp(score_diff, 0)\n",
    "\n",
    "# for a symmetric distribution, the p-value of a one-tailed test is just the half of \n",
    "# the p-value for a two-tailed test\n",
    "\n",
    "p_value = ttest_result[1]/2\n",
    "alpha = .05\n",
    "\n",
    "if p_value < alpha: \n",
    "    print('p_value = {}.  Reject the null hypothesis: Therefore, Our training in Statistical \\\n",
    "    Data Analysis improved students skills'.format(round(p_value,7)))\n",
    "else:\n",
    "    print('p_value = {}, CANNOT Reject the null hypothesis: we do not have enough evidence that \\\n",
    "    our training in Statistical Data Analysis improved students skills'.format(round(p_value,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "# note: greater than not implemented for scipy. Two-sided test done here. \n",
    "_, p = ttest_rel(score.Score2, score.Score1)\n",
    "p_value = p/2\n",
    "\n",
    "if p_value < alpha: \n",
    "    print('p_value = {}.  Reject the null hypothesis: Therefore, Our training in Statistical \\\n",
    "    Data Analysis improved students skills'.format(round(p_value,7)))\n",
    "else:\n",
    "    print('p_value = {}, CANNOT Reject the null hypothesis: we do not have enough evidence that \\\n",
    "    our training in Statistical Data Analysis improved students skills'.format(round(p_value,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hypothesis testing for more than two samples <a name=\"ntests\"></a>\n",
    "## C ---> Q <a name=\"ctoqn\"></a>\n",
    "### Comparing More Than Two Means—ANOVA<a name=\"anova\"></a>\n",
    "So far, we have discussed the two samples and matched pairs designs, in which the categorical explanatory variable has two values. In these cases, examining the relationship between the explanatory and the response variables amounts to comparing the mean of the response variable $y$ in two populations, defined by the two values of the explanatory variable $x$. The difference between the two samples and matched pairs designs is that in the former, the two samples are independent (not paired), and in the latter, the samples are dependent (paired).\n",
    "\n",
    "We are now moving on to cases in which the categorical explanatory variable takes more than two values.\n",
    "\n",
    "\n",
    "<img src='../images/ANOVA.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "A drug company tested three types of pain relief medication for migraines. For the experiment, 27 volunteers were selected and 9 were randomly assigned to each of the three drug formulations. The subjects were instructed to take the drug during their next migraine headache episode and to report their pain on a scale of 1 to 10 (10 being most pain).</font>\n",
    "<br>\n",
    "<table border=1><th>Groups</th><th>Collected data</th>\n",
    "<tr><td>Drug A</td><td>4 3 4 4 4 5 4 3 2 </td></tr>\n",
    "<tr><td>Drug B</td><td>4 6 5 8 6 6 8 4 5 </td></tr>\n",
    "<tr><td>Drug C</td><td>7 5 6 5 5 6 7 6 6 </td></tr>\n",
    "</table>\n",
    "\n",
    "The hypotheses can be stated as follows:\n",
    "- $H_0: \\mu_A = \\mu_B = \\mu_C$\n",
    "- $H_a:$ not all the $\\mu$s are equal\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migraine = pd.DataFrame({\n",
    "    'pain': [4, 3, 4, 4, 4, 5, 4, 3, 2, 4, 6, 5, 8, 6, 6, 8, 4, 5, 7, 5, 6, 5, 5, 6, 7, 6, 6], \n",
    "    'drug': np.repeat([\"A\", \"B\", \"C\"], 9)\n",
    "})\n",
    "\n",
    "migraine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_A = migraine.loc[migraine.drug == \"A\", 'pain']\n",
    "pain_B = migraine.loc[migraine.drug == \"B\", 'pain']\n",
    "pain_C = migraine.loc[migraine.drug == \"C\", 'pain']\n",
    "pain_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to compute ANOVA in Python. Firstly, we can use `scipy.stats.f_oneway`, which returns the f-statistic and the p-value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution 1:\n",
    "from scipy.stats import f_oneway \n",
    "f_stat, p_value = f_oneway(pain_A, pain_B, pain_C)\n",
    "print('f_stat = ', f_stat)\n",
    "print('p_value = ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistic we are concerned about is the F-statistic: $$f_{k-1,n-k} \\sim \\frac {Variation\\,Between\\,Sample\\,Means}{Variation\\,Within\\,Groups} $$\n",
    "\n",
    "Under the null hypothesis that there's no difference in group means, the F-statistic is expected to be around 1. Contrast this with our F-statistic 11.91! Should we reject our hypothesis that there's no difference in group means? \n",
    "\n",
    "Note that you can also compute the F-statistic by taking the ratio of `mean_sq` (mean square error) of `drug` - the 'between-group variation' - to the `mean_sq` of `Residual` - the 'within groups' variation. \n",
    "\n",
    "Together with the degrees of freedom, this gives us a p-value of 0.0003. So, we clearly reject the null hypothesis of equal means for all three drug groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-distribution has two degrees of freedom parameters, $k-1$ and $N-k$, where $N$ is the sample size and $k$ the number of groups. Knowing this, we can recompute the p-value based on the f-statistic:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "N, k = 27, 3\n",
    "df_between, df_within = k-1, N -k \n",
    "p_value = 1 - f.cdf(f_stat, dfn = df_between, dfd = df_within)\n",
    "print('p_value = ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a boxplot based on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('drug', 'pain', data = migraine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple testing \n",
    "Knowing that the means of A, B and C are not equal, we might want to know which pairs of drugs have different levels of pain. You could do a series of pairwise t-tests, i.e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_AB = ttest_ind(pain_A, pain_B, equal_var=False)[1]\n",
    "p_BC = ttest_ind(pain_B, pain_C, equal_var=False)[1]\n",
    "p_AC = ttest_ind(pain_A, pain_C, equal_var=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(pain_A, pain_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have to correct for multiple testing. The more tests you run, the more likely you'll incorrectly find a significant result in any one pair of results by chance alone. The Bonferroni correction simply sets the significance threshold to be $$\\alpha/m$$ where $m$ is the number of hypotheses tested, and $\\alpha$ is the level of significance. \n",
    "\n",
    "In our case, 3 hypotheses are being tested, so divide alpha by 3 to obtain 0.167. Compare this against our array of p-values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([p_AB, p_BC, p_AC]), np.array([p_AB, p_BC, p_AC]) < .05/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows a significant difference between groups A and B and groups A and C but not groups A and C. \n",
    "\n",
    "`statsmodels.sandbox.stats.multicomp.multipletests` is a convenient wrapper function for this procedure. It returns four objects, but we'll focus on three: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "reject, pvals_corrected, _, alphaBonferroni  = multipletests([p_AB, p_BC, p_AC], alpha = .05, method='bonferroni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first object returned, `reject`, provides the result of the multiple testing without the p-values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should you want to compare the p-values against the original level of alpha, it is equivalent to correct the p-values by multiplying the p-values by the number of hypotheses being tested: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multipletests` also returns the Bonferroni-corrected level of alpha: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([p_AB, p_BC, p_AC]), np.array([p_AB, p_BC, p_AC]) < alphaBonferroni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C ---> C<a name=\"ctoc\"></a>\n",
    "\n",
    "The last three procedures that we studied (two-sampled t, paired t, and ANOVA) all involve the relationship between a categorical explanatory variable, $x$, and a quantitative response variable, $y$. Next, we will consider inferences about the relationship between two categorical variables.\n",
    "\n",
    "### Chi-square test for equality of proportions in two samples <a name=\"chisq\"></a>\n",
    "\n",
    "For the test of proportion to be valid, we generally need the following:\n",
    "\n",
    "- For a right- or left-tailed test, a minimum of 10 successes and 10 failures in each group are necessary. \n",
    "- Two-tailed tests are more robust and require only a minimum of 5 successes and 5 failures in each group \n",
    "\n",
    "<img src='../images/ChiSq.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "A researcher wants to know if there's a relationship between gender and drunk-driving. She samples a total of 619 drivers under 20 years of age in a roadside survey.\n",
    "\n",
    "$x$: Driver gender (Male/Female) \n",
    "\n",
    "$y$: Driver alcohol (Yes/No)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Stating the hypotheses\n",
    "- $H_0:$ There is no relationship between the two categorical variables. (They are independent.)\n",
    "- $H_a:$ There is a relationship between the two categorical variables. (They are not independent.)\n",
    "\n",
    "**Step 2**: Checking the Conditions and Calculating the Test Statistic\n",
    "\n",
    "![](../images/AlcoGen.png)\n",
    "![](../images/AlcoGenPerc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 619 sampled drivers, a larger percentage of males were found to be drunk than females (16.0% vs. 11.6%). Our data, in other words, provide some evidence that drunk driving is related to gender; however, this in itself is not enough to conclude that such a relationship exists in the larger population of drivers under 20. We need to further investigate the data and decide between the following two positions:\n",
    "\n",
    "* The evidence provided by the roadside survey (16% vs 11.6%) is strong enough to conclude (beyond a reasonable doubt) that it must be due to a relationship between drunk driving and gender in the population of drivers under 20.\n",
    "* The evidence provided by the roadside survey (16% vs. 11.6%) is not strong enough to make that conclusion, and could have happened just by chance, due to sampling variability, and not necessarily because a relationship exists in the population.\n",
    "\n",
    "These two different conclusions can be condensed into the two hypotheses below: \n",
    "\n",
    "- $H_0:$ Drunk driving and gender are independent\n",
    "- $H_a:$ Drunk driving and gender are not independent\n",
    "\n",
    "Algebraically, independence between gender and driving drunk is equivalent to having equal proportions who drank (or did not drink) for males vs. females. In fact, the null and alternative hypotheses could have been re-formulated as\n",
    "\n",
    "- $H_0:$ proportion of male drunk drivers = proportion of female drunk drivers\n",
    "- $H_a:$ proportion of male drunk drivers ≠ proportion of female drunk drivers\n",
    "\n",
    "Applying the rule to the first (top left) cell, if driving drunk and gender were independent then:\n",
    "\n",
    "$P(drunk\\, and\\, male) = P(drunk) * P(male)$\n",
    "\n",
    "$P(drunk) = 93 / 619$\n",
    "\n",
    "$P(male) = 481 / 619$\n",
    "\n",
    "$P(drunk\\, and \\,male) = (93 / 619)*(481 / 619)$\n",
    "\n",
    "Therefore, since there are total of 619 drivers, if drunk driving and gender were independent, the count of drunk male drivers that I would expect to see is:\n",
    "\n",
    "**Number of drunk Men** = 619* P(drunk and male) = $619 * \\frac {93}{619} * \\frac {481}{619}$\n",
    "\n",
    "Similarly:\n",
    "\n",
    "**Number of drunk Women** = 619* P(drunk and female) = $619 * \\frac {93}{619} * \\frac {138}{619}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/ExpObs.png)\n",
    "\n",
    "$$\\chi^2=\\Sigma_{all\\_cells}\\frac{(Observed\\,Count-Expected\\,Count)^2}{Expected\\,Count}$$\n",
    "\n",
    "The p-value obtained can be interpreted as the probability of observing a $\\chi^2$ test statistic at least as large as the one observed if drunk driving and gender are independent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Given two categorical variables $x$ and $y$, the p-value can be found as:\n",
    "\n",
    "```python\n",
    "1 - chi2.cdf(chi2_stat, df)\n",
    "``` \n",
    "\n",
    "where `chi2_stat` is the $\\chi^2$ test statistic, and $df = (n_A-1)(n_B-1)$ where `n_A` is the number of categories in $x$ and `n_B` is the number of categories in $y$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "An ice cream shop wants to know whether men and women have different preferences for eating their ice cream out of a cone or a bowl. They take a sample of 500 customers (240 men and 260 women) and ask if they prefer cones over bowls. They found that 124 men preferred cones and 90 women preferred cones. Is there a difference in preference between men and women?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = pd.DataFrame({\n",
    "    'IceCream': np.repeat(['cones', 'bowl', 'cones', 'bowl'], repeats=[124, 116, 90, 170]),\n",
    "    'Gender': np.repeat(['male', 'female'], repeats = [240, 260])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.crosstab` returns a contingency table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_table = pd.crosstab(observed.Gender, observed.IceCream)\n",
    "cont_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us work through this slowly to understand the concept of expected counts. Recall that the table of expected counts is what you would expect in each cell of the contingency table if each of the categorical variables of interest were independent, i.e. $$\\Pr(A \\cap B)=\\Pr(A)\\times \\Pr(B)$$\n",
    "\n",
    "If you were to get the number of events where $A \\cap B$, multiply the number of events A and B and divide by the total number of events. (Multiply both sides of the equation by the number of elements in the contingency table, and this should become clear.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icecream_probs = observed.IceCream.value_counts() \n",
    "gender_probs = observed.Gender.value_counts()\n",
    "\n",
    "names = [(i, j) for j in gender_probs.index for i in icecream_probs.index]\n",
    "exp_list = [(i * j)/500 for j in gender_probs for i in icecream_probs]\n",
    "\n",
    "list(zip(names, exp_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is tedious. Fortunately, `scipy.stats.contingency` has an `expected_freq` function that simplifies this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = cont_table.values\n",
    "from scipy.stats.contingency import expected_freq\n",
    "exp = expected_freq(cont_table)\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the chi-square test statistic: \n",
    "$$\\chi^2=\\Sigma_{all\\_cells}\\frac{(Observed\\,Count-Expected\\,Count)^2}{Expected\\,Count}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_stat = np.sum((((obs-exp)**2)/exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the chi-square test statistic quantifies how far away the observed counts are from the expected counts. This makes it similar to the 'greater than' (Case 2) hypotheses tests, and therefore makes it a one-tailed test. The chi-square test has $(r-1)(c-1)$ degrees of freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 2, 2\n",
    "df = (r-1)*(c-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value, under the null of independence, is calculated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "1 - chi2.cdf(chi2_stat, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything we've done previously can be done in one step on our contingency table using the `scipy.stats.chi2_contingency` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "stat, p, dof, expected = chi2_contingency(cont_table, correction=False)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Example</b>\n",
    "<p>\n",
    "    \n",
    "**Risk Factors for Low Birth Weight**\n",
    "    \n",
    "Low birth weight is an outcome that has been of concern to physicians for years. This is due to the fact that infant mortality rates and birth defect rates are very high for babies with low birth weight. A woman's behavior during pregnancy (including diet, smoking habits, and obtaining prenatal care) can greatly alter her chances of carrying the baby to term and, consequently, of delivering a baby of normal birth weight. \n",
    "\n",
    "In this exercise, we will use a 1986 study (Hosmer and Lemeshow (2000), Applied Logistic Regression: Second Edition) in which data were collected from 189 women (of whom 59 had low birth weight infants) at the Baystate Medical Center in Springfield, MA (an academic, research, and teaching hospital that serves as the western campus of Tufts University School of Medicine and is the only Level 1 trauma center in western Massachusetts). The goal of the study was to identify risk factors associated with giving birth to a low birth weight baby.\n",
    "\n",
    "**Variables:**\n",
    "\n",
    "- LOW: Low birth weight (0=No (birth weight >= 2500 g) 1=Yes (birth weight < 2500 g)\n",
    "- AGE: Age of mother (in years)\n",
    "- LWT: Weight of mother (in pounds)\n",
    "- RACE: Race of mother (1=White, 2=Black, 3=Other)\n",
    "- SMOKE: Smoking status during pregnancy (0=No, 1=Yes)\n",
    "- PTL: History of premature labor (0=None, 1=One, etc.)\n",
    "- HT: History of hypertension (0=No, 1=Yes)\n",
    "- FTV: Number of physician visits during the first trimester\n",
    "- BWT: The actual birth weight (in grams)\n",
    "\n",
    "**Question:**\n",
    "- Q1. Do the data provide evidence that the occurrence of low birth weight is significantly related to whether or not the mother smoked during pregnancy?\n",
    "\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Birth = pd.read_csv('../data/low_birth_weight.csv')\n",
    "Birth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question1:\n",
    "cont_table1 = pd.crosstab(Birth.LOW, Birth.SMOKE)\n",
    "cont_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1, p_value1, dof1, expected1 = chi2_contingency(cont_table1, correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value1 < alpha: \n",
    "    print('p_value = {}.  There IS significant relationship between low birth weight and mother smoking habit'.format(round(p_value1,7)))\n",
    "else:\n",
    "    print('p_value = {}, There IS NOT relationship between low birth weight and mother smoking habit'.format(round(p_value1,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "<b>Exercise</b>\n",
    "<p>\n",
    "Answer Questions 2-4:\n",
    "    \n",
    "- Q2. Do the results of the study provide significant evidence that the race of the mother is a factor in the occurrence of low birth weight?\n",
    "\n",
    "- Q3. Are there significant differences in age between mothers who gave birth to low weight babies and those whose baby's weight was normal?\n",
    "\n",
    "- Q4. Are there significant relationship between the actual birth weight and the race of the mother?\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "## Recreating ANOVA table from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with group means of pain \n",
    "migraine['group_means'] = migraine.groupby('drug').transform('mean')\n",
    "N, k = 27, 3\n",
    "df_between, df_within = k-1, N-k\n",
    "\n",
    "# sum of squares **within** treatment groups\n",
    "# and total sum of squares\n",
    "sum_sq_within = sum((migraine.pain - migraine.group_means)**2)\n",
    "sum_sq_total = sum((migraine.pain - np.mean(migraine.pain))**2)\n",
    "\n",
    "# the between sum of squares is just the diff betweeen total and within sum of squares\n",
    "sum_sq_between = sum_sq_total - sum_sq_within\n",
    "\n",
    "mean_sq_between, mean_sq_within = sum_sq_between/df_between, sum_sq_within/df_within\n",
    "\n",
    "F_stat = mean_sq_between/mean_sq_within\n",
    "\n",
    "# right-tailed hypothesis test - are the means within each of the groups the \n",
    "# same as the population mean? > 1 if different. \n",
    "p_value = 1 - f.cdf(F_stat, dfn = df_between, dfd = df_within)\n",
    "\n",
    "# sum_sq_between - the between-group variation - is the 'explained' sum of squares\n",
    "# this metric is known as the r-squared\n",
    "sum_sq_between / sum_sq_total\n",
    "\n",
    "1 - sum_sq_within/sum_sq_total\n",
    "\n",
    "pd.DataFrame([[df_between, sum_sq_between, mean_sq_between, F_stat, p_value], \n",
    "              [df_within, sum_sq_within, mean_sq_within, np.nan, np.nan]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, you can use the observed and expected values to run the chi-square test of independence using the `chisquare` function from `scipy.stats`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "_, p = chisquare(obs.ravel(), exp.ravel(), ddof=sum(obs.shape)-2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `ravel()` method is needed because without it, `chisquare` will calculate the chi-square statistic for each column. \n",
    " \n",
    "`scipy.stats.chisquare` takes a **delta** degrees of freedom (ddof) parameter. This is a bit tricky to characterise. Recall that the degrees of freedom of the test of indepdence is $$df = (r-1)(c-1)$$ where $r$ is the number of rows, and $c$ is the number of columns. \n",
    "\n",
    "`chisquare` uses a chi-square distribution with $k-1-ddof$ degrees of freedom, where $k = rc$, the number of frequencies observed. With a bit of algebraic manipulation, we obtain ddof as $r+c-2$.  \n",
    "\n",
    "$$(r-1)(c-1)=rc-r-c+1= rc-(r+c-2)-2+1=rc-1-(r+c-2)$$\n",
    "\n",
    "`scipy.stats.chisquare` returns the chi-square statistic and the p-value. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
